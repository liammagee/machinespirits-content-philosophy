# AI Dissertation Group

## Slide 1

### **Back to the** Litera**ture…**  

---

## Slide 2

### Dissertation > Publication  

| | |
|---|---|
| Why publish?<br>Peer review **for real **(no longer polite)<br>Get **noticed** / **cited**<br>**Adds weight** to public speaking / presentations / promotion / job interview<br>During / after the dissertation?<br>During: can help **“sell” complex arguments** to examiners - “this has already been peer reviewed”<br>After: convert the full dissertation to a book monograph / series of articles<br><br> | How to publish?<br>Take chapters (e.g. lit review) as standalone articles<br>Blend and summarize parts of the dissertation (Intro / lit review / methods / findings)<br>Consider<br>Journals (Q1, but quality not the only criteria)<br>Preprint servers (arxiv, edarxiv, socsciarxiv, SSRN)<br>Conferences<br>Medium / Substack<br>Other formats: YouTube, blogposts etc<br><br> |

---

## Slide 3

### Some Observations  

| | |
|---|---|
| General and Special Field Exams are very long<br>Final length: roughly 6k for General / 4k words for Special: ~10K for Chapter 2<br>But some are (combined) ~20k<br>This produces several effects:<br>Lots to write (student) / lots to read (advisor) / lots to edit (student) / lots to examine<br>Tolerance for length less and less, across all venues / genres (journals, books etc) - generative AI effect? (publishers & editors inundated)<br>Most importantly: the argumentative *effect* of the literature review is lost<br>Loss of sight of the forest for the trees<br>Becomes an exercise in *voluminous* and *encyclopaedic* rather than *persuasive* and *forensic* writing<br><br> |  |

---

## Slide 4

### Accumulative  

| | |
|---|---|
| Authors X suggest this. And Authors Y show evidence that. Authors Z also argue… Everything is a consensus, new findings simply **accumulate**…<br>But academia is not like that – it is often rift, agonistic, full of micro-dramas and antipathies…<br>No need to manufacture debate where none exists, but is often helpful to show *disagreement / dissensus*.<br>Use contrastive conjunctions: “**While** authors X suggest this, authors Y **instead** show evidence that…” (where *this* and *that* could be opposed)<br>Show distinctions of emphasis *even within* consensus: “The literature shows broad consensus around the benefits of …, **but** scholars have emphasised different features. For example, **on the one hand**, authors X suggest…, **while on the other**, authors Y emphasize that”<br>Why? Makes clearer to the reader something of the **live debates** in relation to your topic / question. It makes things seem less settled, and therefore provides greater impetus to your own research. Get your reader to think: “this thing really needs to be clarified”<br><br> |  |

---

## Slide 5

### Headings and Signposting  

| | |
|---|---|
| Use Heading Levels – Simplifies navigation, shows organization<br>Heading 1<br>Subheading 1<br>“X et al. (2024) argue that…. Y (2024) suggest …”<br>Include so-called “sign-posting”, transition sentences<br>Introducing and Outlining Sections: “The following sections…” / “In the following sections I discuss<br>Connecting Sections “This section discussed” / “In this section I discussed”... <br>Concluding a series of sections<br>A note on first person<br>I’m fine with it!<br>But use first person to control flow, rather than indicate opinion:<br>“In the next section, I…”<br>NOT “I really find Magee (2024) profoundly mistaken…”<br><br> |  |

---

## Slide 6

### From Vibe coding to vibe reviewing  

| | |
|---|---|
| See Karpathy on live coding…<br>But why not “vibe reviewing”? Use gen AI to schematize – quick overall structures, short passages in the “review” genre – break writer’s block<br><br> |  |

---

## Slide 7

### Exaggerated Example (GPT-o1) - no signposting  

| | |
|---|---|
| **A Very Disconnected Literature Review on AI in Education**<br>Some teachers are enthusiastic about using AI systems in the classroom, mostly because they think robots look cool. In 2015, Mendez discovered that very few students actually enjoyed any form of computer-based instruction, though no one is really sure if these findings are widely applicable. Meanwhile, many students prefer video games at home.<br>When considering the impact of AI on grading, Jones (2020) notes that automated essay scoring can be inaccurate, but also states that it sometimes provides better feedback than humans. However, this is not directly related to whether teachers find AI grading platforms easy to use, nor does it address the question of budget constraints in public schools.<br>Sato (2019) claims that implementing AI labs in schools could reduce the cost of textbooks. Elementary school teachers, on the other hand, often cite the difficulty of explaining machine learning to children in kindergarten, although most references to these difficulties appear in medical journals. Attendance rates in these schools do not seem to change when new software is introduced.<br>Nothing conclusive has been reported about how teachers feel in the long term, especially in rural districts, and the subject often veers toward discussions of e-books or cafeteria meal plans. Park and Green (2021) mention that AI has a major impact on student mindset but do not specify what that impact is, making the findings hard to interpret. Some older studies even focus on the psychology of the 1980s arcade era, tying it vaguely to modern AI-based learning tools.<br>Though some researchers point to improved standardized test scores, others say it’s more important to evaluate intangible outcomes. O’Neill (2022) briefly suggests that AI can predict how many students will pick pizza over salad for lunch. It is unclear how this affects lesson planning, if at all. No further details are provided, and data analysis remains incomplete.<br><br> |  |

---

## Slide 8

### Exaggerated Example (GPT-o1) - over-signposting  

| | |
|---|---|
| **Introduction**<br>In this section, I intend to lay the groundwork for an exploration of artificial intelligence (AI) in education. Following this introduction, each section of this review will elaborate on a distinct aspect of the literature, moving from teacher enthusiasm to student preferences, then progressing to grading technologies, and ultimately culminating in a discussion of empirical indicators and future possibilities. By repeatedly connecting back to previously presented studies, this literature review seeks to create a sense of continuous narrative, despite the fact that some of the underlying findings are rather incongruous.<br>**1. Teacher Enthusiasm Versus Student Preferences**<br>*Having introduced the overall topic of AI in education, it is instructive to begin by exploring the apparent divide between teacher excitement and student reactions to technology in classrooms.* … *This paradox sets the stage for further inconsistencies we will uncover in the next sections.***2. The Impact of AI on Grading**<br>*Having acknowledged teacher–student tensions in the preceding section, I now turn to the matter of AI-driven grading systems. *… *However, as the following section will show, the question of school budgets and infrastructure often tangentially intersects with educational objectives, thus creating new layers of complexity. …*<br>**6. Empirical Indications and Future Possibilities**<br>*Shifting from mindset discussions, the review now touches on attempts to quantify the effect of AI.* …  The final section brings these disparate elements together, underscoring the inherent fragmentation and highlighting the need for deeper, more unified research efforts.<br>**Conclusion**<br>In summation, this review has traversed a broad terrain, moving systematically from teacher excitement and student doubts, to AI-based grading systems, and on through the realities of budgeting and long-term educator perspectives. Each section has spotlighted inconsistencies,  …. Ultimately, future research should consider more robust approaches to link these topics, integrate contradictory findings, and fill the evident gaps in our understanding of AI’s place in education.<br><br> |  |

---

## Slide 9

### Exaggerated Example (GPT-o1)   Yes it is exaggerated, but I’d encourage practicing: Headings / subheadings for sections / subsections (using Word / HTML heading levels) Short introductions and conclusions to major sections Connecting sentences between lengthy subsections Why? Literature Reviews are examples of Persuasive Writing What are you persuading someone of? There there really is a **gap** in the literature, the gap is **significant**, and you aim to **fill it with your research**. What don’t you need to persuade someone of? That the “Literature” argues X - or that your literature, collectively, is in **furious agreement** That there are **many topics** you need to cover with many sections: *Salience *or *relevance* in topic selection is welcomed Feel free to explain why you are *not exhaustive*: “There is this literature over there, but I’m not touching that because it isn’t relevant to my exact topic… however, future work might seek to engage with those findings” etc That you have read *everything *in the field That there are *many* gaps In re-reading your general and special field exams, read also for persuasiveness: have you convinced yourself that there is a **significant gap that your research can fill**? If not, why not?  

---

## Slide 10

### Exaggerated Example (GPT-o1)   **Prompt:** “Add headings and signposting, to make this review more coherent. Include an introduction, and conclusion, with sentences connecting the sections. Go overboard with the signposting” *(Not happy with the example, for demonstration purposes)* “Do it again, adding even more signposting to link sections together”  

---

## Slide 11

### AI & Literature Reviews   *It’s a terrible idea:* **Invents** citations Doesn’t **identify gaps** Makes **spurious** arguments Is always **out-of-date** It doesn’t understand **the dissertation context** It **loses coherence** due to word length Its writing is **uninteresting / banal** It is **plagiarism**   *It’s a great idea:* **Practice **re-drafting sections and sub-sections for sign-posting Ask AI to be “Reviewer 2” and read your section / chapter through an **exaggerated critical** lens Add one or more PDFs from your literature for context, and ask whether your **own summary of their positions** is accurate Test for coherence, persuasiveness and whether the gap is (a) **really there**, (b) **significant** and (c) **feasible** to address in a dissertation Use CyberScholar, but also “raw” AI tools, where you can copy / paste chunks and outlines, and **iterate** with your interactions Use *NotebookLM* and other tools to **build podcasts** about your literature review (general field, special field, or both). Do the results **makes sense**? Do you feel **misunderstood**? **Be specific**: use small samples or outlines, get ideas for writing strategies, but also **critically assess** the AI feedback It will be (for some time) **inaccurate** with actual references - upload PDFs rather than ask “what are critiques of  Amartya Sen’s Capabilities Approach?”  

---

## Slide 12

### Practice?   Thoughts on good prompts?  Any candidates?  

---

